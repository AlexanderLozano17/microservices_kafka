# ğŸ“¦ Proyecto Spring Boot + Apache Kafka (Docker Ready)

Este proyecto demuestra cÃ³mo integrar ** Spring Boot**  con ** Apache Kafka** , permitiendo enviar, recibir y almacenar mensajes en formato **JSON**  de manera eficiente. AdemÃ¡s, utilizamos **Docker Compose**  para simplificar la configuraciÃ³n y ejecuciÃ³n del entorno, y **Kafka UI** para visualizar y monitorear en tiempo real los tÃ³picos, mensajes y el estado del broker Kafka.

El proyecto de Spring Boot estÃ¡ desarrollado de manera modular, lo que facilita la escalabilidad, mantenimiento y separaciÃ³n de responsabilidades.

Adicionalmente, se incorpora un enfoque de arquitectura de microservicios utilizando Spring Cloud Netflix Eureka como servidor de descubrimiento para registrar y localizar automÃ¡ticamente los distintos servicios del sistema. TambiÃ©n se incluye un **API Gateway** basado en **Spring Cloud Gateway**, que actÃºa como punto de entrada Ãºnico, gestionando el enrutamiento, autenticaciÃ³n y filtrado de solicitudes hacia los microservicios registrados en **Eureka**.


## ğŸ› ï¸ TecnologÃ­as Utilizadas

| TecnologÃ­a          			 | DescripciÃ³n                                                   |
|--------------------------------|---------------------------------------------------------------|
| **Java 17**         			 | Lenguaje de programaciÃ³n principal                            |
| **Spring Boot**     			 | Framework para desarrollo rÃ¡pido de aplicaciones Java         |
| **Spring Cloud Netflix Eureka**| Registro y descubrimiento de servicios                        |
| **Spring Cloud Gateway **      | punto de entrada centralizado para todas las solicitudes HTTP |
| **Spring Data JPA** 			 | AbstracciÃ³n para el acceso a datos con repositorios           |
| **Spring Kafka**    			 | Cliente Kafka para integraciÃ³n con Spring                     |
| **Apache Kafka**    			 | Plataforma distribuida de mensajerÃ­a                          |
| **Kafka UI**        			 | Interfaz grÃ¡fica para gestionar Kafka                         |
| **Zookeeper**       			 | Coordinador de servicios para Kafka                           |
| **OpenAPI** 		  			 | DocumentaciÃ³n interactiva de la API REST 				     |
| **Docker**          			 | ContenedorizaciÃ³n de la aplicaciÃ³n                            |
| **Docker Compose**  			 | OrquestaciÃ³n de contenedores                                  |
| **Jackson**         			 | SerializaciÃ³n y deserializaciÃ³n JSON                          |
| **Maven**           			 | GestiÃ³n del ciclo de vida del proyecto Java                   |


## ğŸ’¡ Buenas prÃ¡cticas y patrones aplicados

- âœ… Uso de **DTO (Data Transfer Object)** para desacoplar entidades del modelo de datos
- âœ… ImplementaciÃ³n de **JPQL (Java Persistence Query Language)** para consultas personalizadas
- âœ… Arquitectura por capas: `Controller â†’ Service â†’ Repository`
- âœ… Manejo de errores y trazabilidad con **logs estructurados (SLF4J + LogHelper)**
- âœ… Anotaciones clave como `@Transactional`, `@Service`, `@Repository`, `@Slf4j`
- âœ… ValidaciÃ³n de entradas con `@Valid` y uso de clases request/response especÃ­ficas
- âœ… Uso de excepciones personalizadas y manejo centralizado de errores

---



## ğŸ“˜ Arquitectura del Proyecto

Puedes ver la arquitectura de microservicios en el siguiente PDF:

ğŸ‘‰ [Ver arquitectura C4 en PDF](docs/arquitectura.pdf)

## **ğŸ“Œ Estructura del Proyecto Event-Driven Architecture**

```
ğŸ“ microservices
â”œâ”€â”€ ğŸ“ producer                 # Microservicio multi-mÃ³dulo (parent POM adentro)
â”‚   â”œâ”€â”€ ğŸ“ main-app             # Punto de entrada Spring Boot
â”‚   â”œâ”€â”€ ğŸ“ module-core          # LÃ³gica de negocio principal
â”‚   â”œâ”€â”€ ğŸ“ module-producer      # Productor de mensajes Kafka
â”‚   â”œâ”€â”€ ğŸ“ module-dto           # Data Transfer Objects (DTO)
â”‚   â”œâ”€â”€ ğŸ“ module-common        # Utilitarios, constantes, logs, etc.
â”‚   â”œâ”€â”€ ğŸ“„ pom.xml              # POM raÃ­z del proyecto producer
â”œâ”€â”€ ğŸ“ api-gateway	           # Microservicio api gate-way
â”œâ”€â”€ ğŸ“ eureka-server	           # Registro y descubrimiento de servicios 
â”œâ”€â”€ ğŸ“ consumer-person          # Microservicio consumidor de mensajes de persona
â”œâ”€â”€ ğŸ“ consumer-publication     # Microservicio consumidor de publicaciones
â”œâ”€â”€ ğŸ“ consumer-commentary      # Microservicio consumidor de comentarios
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml       # Servicios Kafka, Zookeeper y Kafka UI
â””â”€â”€ ğŸ“„ README.md                # DocumentaciÃ³n general del sistema


```
Producer esta diseÃ±o modular permite mayor **reutilizaciÃ³n** y **mantenibilidad**.

---

## **ğŸ“ Logging**
Se utiliza **SLF4J** junto con un helper personalizado (**LogHelper**) para estructurar los logs.
Cada acciÃ³n del sistema (inicio, Ã©xito, error, fin) es registrada, facilitando la trazabilidad y el anÃ¡lisis de errores.

---


## ğŸš€ Pasos para ejecutar el proyecto

 **Paso 1: Clonar el repositorio:**

   ```bash
   git clone https://github.com/AlexanderLozano17/microservices_kafka.git
   ```

 **Paso 2: Renombrar archivos `.yml`:**  
 
	Reemplaza los nombres de los archivos de configuraciÃ³n eliminando la palabra `template` del nombre.  
	Por ejemplo:
	
	
	application-template.yml â†’ application.yml
	docker-compose-template.yml â†’ docker-compose.yml
	

 **Paso 3: Verificar que Docker estÃ© instalado:**  

   AsegÃºrate de tener Docker y Docker Compose funcionando en tu mÃ¡quina.
   
   ```bash
   docker --version
   ```

 **Paso 4: Levantar los contenedores:**  

   Desde la raÃ­z del proyecto, ejecuta:
   
   ```bash
   docker-compose up -d --build
   ```

 **Paso 5: erificar que los contenedores estÃ©n corriendo:**

   ```bash
   docker ps
   ```

 **Paso 6: Acceder a Kafka UI:**  

   Visualiza y administra los topics desde:  
   
   ```bash
   ğŸ‘‰ [http://localhost:8080](http://localhost:8080)
   ```
   
### **Crear los topics (si no se crean automÃ¡ticamente):**

   ```bash
   docker exec -it kafka1 kafka-topics.sh --create --topic topic-persons --bootstrap-server kafka1:9092 --partition 3 --replication-factor 1
   docker exec -it kafka1 kafka-topics.sh --create --topic topic-publications --bootstrap-server kafka1:9092 --partition 3 --replication-factor 1
   docker exec -it kafka1 kafka-topics.sh --create --topic topic-commentaries --bootstrap-server kafka1:9092 --partition 3 --replication-factor 1
   ```

### **DocumentaciÃ³n de la API REST:**  
   Accede a Swagger UI para ver los endpoints disponibles:  
   
   ```bash
   ğŸ‘‰ [http://localhost:8081/swagger-ui/index.html](http://localhost:8081/swagger-ui/index.html)
   ```
  

---

âœ… Â¡Con esto ya puedes comenzar a trabajar con la arquitectura distribuida basada en Kafka!
