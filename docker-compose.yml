version: '3.9'
services:

  # Contenedor Zookeeper: Es un servicio de coordinacion distribuida que Kafka utiliza para gestionar el cluster de brokers.
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    restart: always
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes  # Permite conexiones sin autenticacion
    ports:
      - "2181:2181"  # Puerto para comunicarse con Kafka
    env_file: # Carga variables de entorno desde un archivo .env
      - .env
    networks:
      - kafka_network
    volumes:
      - zookeeper:/bitnami/zookeeper  # Persistencia de datos de Zookeeper
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "zookeeper", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Contenedor Kafka: Es el broker que gestiona la mensajeria y la transmision de eventos en tiempo real.
  kafka1:
    image: bitnami/kafka:latest
    container_name: kafka1
    restart: always
    depends_on:
      # estás diciendo que NO solo esperar a que el servicio arranque, sino que además esperas a que su healthcheck sea exitoso antes de levantar el contenedor dependiente
      zookeeper:
        condition: service_healthy
    command: ["sh", "-c", "sleep 10 && /opt/bitnami/scripts/kafka/run.sh"] # Retrasa el arranque de Kafka
    ports:
      - "9092:9092"  # Puerto para conexiones internas
      - "29092:29092" # Puerto para conexiones externas
    env_file: # Carga variables de entorno desde un archivo .env
      - .env
    environment:     
      KAFKA_BROKER_ID: 1  # Identificacion del broker
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  # Conexion con Zookeeper

      # Configuracion de los listeners (definen como Kafka acepta conexiones)
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092
      # - INTERNAL: Para conexiones internas dentro del contenedor
      # - EXTERNAL: Para conexiones externas fuera del contenedor

      #  Direcciones que Kafka anuncia a los clientes para conectarse
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:9092,EXTERNAL://${KAFKA_HOST_IP}:29092
      # - INTERNAL: Se usa dentro de la red de Docker con el nombre `kafka1`
      # - EXTERNAL: Se usa fuera de Docker con la IP de la maquina `KAFKA_HOST_IP`

      #  Define que protocolo usa cada listener (solo texto plano en este caso)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT

      # Listener usado para la comunicacion entre brokers
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      #  Configuracion de replicacion (para alta disponibilidad)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 # Replicas del topico __consumer_offsets
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2       # Replicas por defecto en nuevos topicos
      KAFKA_MIN_INSYNC_REPLICAS: 1              # Minimo de replicas sincronizadas antes de aceptar un mensaje
    networks:
      - kafka_network
    volumes:
      - kafka1_data:/bitnami/kafka  # Persistencia de datos de Kafka
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/9092"] 
      retries: 5
      start_period: 30s
      timeout: 10s
      
  # Contenedor Kafka2: Es el broker que gestiona la mensajeria y la transmision de eventos en tiempo real.
  kafka2:
    image: bitnami/kafka:latest
    container_name: kafka2
    restart: always
    depends_on:
      # estás diciendo que NO solo esperar a que el servicio arranque, sino que además esperas a que su healthcheck sea exitoso antes de levantar el contenedor dependiente
      zookeeper:
        condition: service_healthy
    command: ["sh", "-c", "sleep 10 && /opt/bitnami/scripts/kafka/run.sh"] # Retrasa el arranque de Kafka
    ports:
      - "9093:9093"  # Puerto para conexiones internas
      - "29093:29093" # Puerto para conexiones externas
    env_file: # Carga variables de entorno desde un archivo .env
      - .env
    environment:
      KAFKA_BROKER_ID: 2 # Identificacion del broker
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 # Conexion con Zookeeper

      # Configuracion de los listeners (definen como Kafka acepta conexiones)
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:29093
      # - INTERNAL: Para conexiones internas dentro del contenedor
      # - EXTERNAL: Para conexiones externas fuera del contenedor

      # Direcciones que Kafka anuncia a los clientes para conectarse
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:9093,EXTERNAL://${KAFKA_HOST_IP}:29093
      # - INTERNAL: Se usa dentro de la red de Docker con el nombre `kafka2`
      # - EXTERNAL: Se usa fuera de Docker con la IP de la maquina `KAFKA_HOST_IP`

      # Define que protocolo usa cada listener (solo texto plano en este caso)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT

      # Listener usado para la comunicacion entre brokers
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # Configuracion de replicacion (para alta disponibilidad)
      # Replicas del topico __consumer_offsets
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2 
      # Replicas por defecto en nuevos topicos
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2       
      # Minimo de relicas sincronizadas antes de aceptar un mensaje
      KAFKA_MIN_INSYNC_REPLICAS: 1              
    networks:
      - kafka_network
    volumes:
      - kafka2_data:/bitnami/kafka  # Persistencia de datos de Kafka
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/9093"] 
      retries: 5
      start_period: 30s
      timeout: 10s      

  # Contenedor Kafka-UI: Es una interfaz web para visualizar y gestionar Kafka.
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    restart: always
    ports:
      - "8080:8080"  # Puerto para acceder a la interfaz web
    env_file: # Carga variables de entorno desde un archivo .env
      - .env
    environment:
      KAFKA_CLUSTERS_0_NAME: local  # Nombre del cluster en la interfaz
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092,kafka2:9093  # Direccion de los broker de Kafka
    networks:
      - kafka_network
    volumes:
      - kafka-ui-data:/config  # Persistencia de la configuracion de la interfaz
    healthcheck:
      test: ["CMD", "nc", "-z", "kafka-ui", "8080"]  # Verifica que Kafka esté disponible en el puerto 8080
      interval: 30s
      retries: 3
      start_period: 10s
      timeout: 10s

  # Contenedor POSTGRES
  postgres:
    image: postgres:14.4
    container_name: postgresKafka
    restart: always
    ports:
      - "5432:5432"
    # Carga variables de entorno desde un archivo .env
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${SPRING_DATASOURCE_USERNAME}
      POSTGRES_PASSWORD: ${SPRING_DATASOURCE_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres:/var/lib/postgresql/data
    networks:
      - kafka_network    
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "root"]  
      interval: 30s
      retries: 3
      start_period: 10s
      timeout: 10s

  #contendor de eureka server
  eureka-server:
    build:
      context: ./eureka-server      
      dockerfile: Dockerfile       
    container_name: ${EUREKA_CONTAINER_NAME}
    restart: always
    ports:
      - "8761:8761"  
    # Carga variables de entorno desde un archivo .env
    env_file: 
      - .env               
    environment:
      - SPRING_PROFILES_ACTIVE=default
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8761/actuator/health"]
      interval: 30s
      retries: 5
      start_period: 20s
      timeout: 5s

  #contendor de la aplicacion producer
  app-producer:
    build:  # Define como se construye la imagen del contenedor.
      context: ./producer # Usa el directorio actual como contexto de construccion.
      dockerfile: Dockerfile # Especifica el archivo Dockerfile a utilizar    
    container_name: ${PRODUCER_APP_NAME}
    restart: always
    logging:
      driver: json-file
    depends_on:
      - eureka-server
      - postgres
      - kafka1
      - kafka2       
    env_file:
      - .env
    ports:
      - 8081:8081
    networks:
      - kafka_network
    healthcheck:
      #  Verifica que el contenedor esté disponible en el puerto
      test: ["CMD", "curl", "-f", "http://${PRODUCER_APP_NAME}:8081/actuator/health"]  
      interval: 30s
      timeout: 10s
      retries: 5

  #contendor de la aplicacion consumer-person
  app-consumer-person:
    build:  # Define como se construye la imagen del contenedor.
      context: ./consumer-person # Usa el directorio actual como contexto de construccion.
      dockerfile: Dockerfile # Especifica el archivo Dockerfile a utilizar
    container_name: ${CONSUMER_PERSON_APP_NAME}
    restart: always
    depends_on:
      # Está diciendo que NO solo esperar a que el servicio arranque, sino que además esperas a que su healthcheck sea exitoso antes de levantar el contenedor dependiente
      - eureka-server
    logging:
      driver: json-file    
    env_file:
      - .env
    ports:
      - 8082:8082
    networks:
      - kafka_network    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://${CONSUMER_PERSON_APP_NAME}:8082/actuator/health"]  # Verifica que el contenedor esté disponible en el puerto
      interval: 30s
      timeout: 10s
      retries: 5

  #contendor de la aplicacion consumer-publication
  app-consumer-publication:
    build: #  Define como se construye la imagen del contenedor.
      context: ./consumer-publication # Usa el directorio actual como contexto de construccion.
      dockerfile: Dockerfile # Especifica el archivo Dockerfile a utilizar
    container_name: ${CONSUMER_PUBLICATION_APP_NAME}
    restart: always
    depends_on:
      - eureka-server
    logging:
      driver: json-file   
    env_file:
      - .env
    ports:
      - 8083:8083
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://${CONSUMER_PUBLICATION_APP_NAME}:8083/actuator/health"]  # Verifica que el contenedor esté disponible en el puerto
      interval: 30s
      timeout: 10s
      retries: 5

  #contendor de la aplicacion consumer-commentary
  app-consumer-commentary:
    build: #  Define como se construye la imagen del contenedor.
      context: ./consumer-commentary # Usa el directorio actual como contexto de construccion.
      dockerfile: Dockerfile # Especifica el archivo Dockerfile a utilizar
    container_name: ${CONSUMER_COMMENTARY_APP_NAME}
    restart: always
    depends_on:
      - eureka-server
    logging:
      driver: json-file   
    env_file:
      - .env
    ports:
      - 8084:8084
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://${CONSUMER_COMMENTARY_APP_NAME}:8084/actuator/health"]  # Verifica que el contenedor esté disponible en el puerto
      interval: 30s
      timeout: 10s
      retries: 5

  #contendor de api-gateway
  gateway:
    build:
      context: ./api-gateway    
      dockerfile: Dockerfile       
    container_name: ${GATEWAY_APP_NAME}
    restart: always
    depends_on:
      - eureka-server
    logging:
      driver: json-file   
    ports:
      - "8085:8085"                 
    networks:
      - kafka_network
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://${GATEWAY_APP_NAME}:8085/actuator/health"]  # Verifica que el contenedor esté disponible en el puerto
      interval: 30s
      timeout: 10s
      retries: 5

# Red personalizada para la comunicacion entre contenedores
networks:
  kafka_network:
    driver: bridge  

# Volumenes para la persistencia de datos
volumes:
  zookeeper:
  kafka1_data:
  kafka2_data:
  kafka-ui-data:
  postgres:
